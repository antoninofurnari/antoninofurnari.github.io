---
title: "Action anticipation da video mediante rappresentazioni a grafo e Large Language Models"
date: 2024-08-25T17:33:11+02:00
draft: false
teaser: ant-llm.png
---



Il problema della egocentric action anticipation consiste nel predire le prossime azioni da un video acquisito mediante dispositivi indossabili. 

I large language models sono stati recentemente utilizzati con successo per la predizione di azioni future, ma la loro capacità di allucinazione ne limita le performance in diversi casi. I grafi procedurali sono stati recentemente utilizzati come un modo di condificare la conoscenza di una procedura da video. Altri lavori hanno esplorato metodologie per integrare le informazioni fornite dai grafi all'interno di modelli di linguaggio.

Lo scopo della tesi è quello di integrare la conoscenza fornita da un grafo all'interno di un modello LLM per la predizione di azioni future.

Letture di riferimento:
* [Zhao, Q., Wang, S., Zhang, C., Fu, C., Do, M. Q., Agarwal, N., ... & Sun, C. (2023). Antgpt: Can large language models help long-term action anticipation from videos?. arXiv preprint arXiv:2307.16368.](https://arxiv.org/pdf/2307.16368)
* [Seminara, L., Farinella, G. M., & Furnari, A. (2024). Differentiable Task Graph Learning: Procedural Activity Representation and Online Mistake Detection from Egocentric Videos. NeurIPS 2024.](https://arxiv.org/pdf/2406.01486)
* [Fatemi, Bahare, Jonathan Halcrow, and Bryan Perozzi. "Talk like a graph: Encoding graphs for large language models." arXiv preprint arXiv:2310.04560 (2023).](https://arxiv.org/pdf/2310.04560)
* [Perozzi, B., Fatemi, B., Zelle, D., Tsitsulin, A., Kazemi, M., Al-Rfou, R., & Halcrow, J. (2024). Let your graph do the talking: Encoding structured data for llms. arXiv preprint arXiv:2402.05862.](https://arxiv.org/pdf/2402.05862)
